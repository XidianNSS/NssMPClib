{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 2: Arithmetic Secret Sharing\n",
    "Arithmetic secret sharing is used in secure two-party computation, where each participant holds the shared value of the data. In this way the data does not leak information during the calculation process. At present, our model and functions are designed based on semi-honest parties.\n",
    "To use arithmetic secret sharing for secure two-party computation, we import the following packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from model.mpc.semi_honest_party import SemiHonestCS\n",
    "from crypto.primitives.arithmetic_secret_sharing.arithmetic_shared_ring_tensor import ArithmeticSharedRingTensor\n",
    "from common.tensor.ring_tensor import RingTensor\n",
    "from crypto.primitives.beaver.matrix_triples import MatrixTriples\n",
    "\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:54.514628Z",
     "start_time": "2024-03-21T11:20:52.309934Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```SemiHonestCS``` is the two semi-honest party. ```arithmetic_shared_ring_tensor``` is the main package that we use. ```RingTensor``` is the main data structure that we use. ```BeaverProvider``` is the triple provider we use in the arithmetic secret share for multiplication operations, and we use ```BeaverProvider``` to simulate a trusted third party to provide auxiliary operation data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Party\n",
    "First, we need to define the parties involved in the computation. For secure two-party computation, we need two parties: the server and the client.\n",
    "When setting up the parties, we need to specify the address and port for each party. Each party has a tcp server and a tcp client. They all need an address and a port. We also need to set the Beaver triple provider and the wrap provider for the computations. If you are planning to do comparison operations, do not forget to set the compare key provider.\n",
    "In this demonstration we are using multi-threading to simulate two parties. In real applications, the server and client run in two files. You can refer to ``./ debug/crypto/primitives/arithmetic_secret_sharing/test_ass_server.py`` and ```./ debug/crypto/primitives/arithmetic_secret_sharing/test_ass_client.py```."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCPServer waiting for connection ......\n",
      "TCPServer waiting for connection ......\n",
      "successfully connect to server 127.0.0.1:8089\n",
      "TCPServer successfully connected by :('127.0.0.1', 20001)\n",
      "successfully connect to server 127.0.0.1:20000TCPServer successfully connected by :('127.0.0.1', 8088)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# set Server\n",
    "server = SemiHonestCS(type='server')\n",
    "\n",
    "server.set_multiplication_provider()\n",
    "server.set_comparison_provider()\n",
    "\n",
    "\n",
    "def set_server():\n",
    "    # CS connect (self tcp server address) (self tcp client address) (other tcp server address) (other tcp client address)\n",
    "    server.connect(('127.0.0.1', 8089), ('127.0.0.1', 8088), ('127.0.0.1', 20000), ('127.0.0.1', 20001))\n",
    "\n",
    "\n",
    "\n",
    "# set Client\n",
    "client = SemiHonestCS(type='client')\n",
    "\n",
    "client.set_multiplication_provider()\n",
    "client.set_comparison_provider()\n",
    "\n",
    "def set_client():\n",
    "    # CS connect\n",
    "   client.connect(('127.0.0.1', 20000), ('127.0.0.1', 20001), ('127.0.0.1', 8089), ('127.0.0.1', 8088))\n",
    "\n",
    "\n",
    "server_thread = threading.Thread(target=set_server)\n",
    "client_thread = threading.Thread(target=set_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:55.113313Z",
     "start_time": "2024-03-21T11:20:54.515627Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you see two instances of \"successfully connected\", it indicates that the communication between the two parties has been established successfully."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Secret Sharing\n",
    "If both parties have data that they want to compute on without revealing their individual data to each other, you can use the ```share``` method from ```ArithmeticSecretSharing``` (ASS) to perform data sharing. Additionally, you need to utilize TCP to send each party's shares to the other party and receive their own shares.\n",
    "In this case, let's assume that the server has data denoted as x, and the client has data denoted as y."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " shared x in server: ArithmeticSharedRingTensor\n",
      " value:tensor([[ 5466333745128403300, -6395018159207208530],\n",
      "        [  889215137156102987, -4582170111517986136]], device='cuda:0') \n",
      " dtype:float \n",
      " scale:65536\n",
      " party:0\n",
      "\n",
      " shared y in server: ArithmeticSharedRingTensor\n",
      " value:tensor([[ 7272982348057240323, -5783740582566321592],\n",
      "        [  150646293732089090, -1493090933781434579]], device='cuda:0') \n",
      " dtype:float \n",
      " scale:65536\n",
      " party:0\n",
      "\n",
      " shared x in client: ArithmeticSharedRingTensor\n",
      " value:tensor([[-5466333745128337764,  6395018159207339602],\n",
      "        [ -889215137155906379,  4582170111518248280]], device='cuda:0') \n",
      " dtype:float \n",
      " scale:65536\n",
      " party:1\n",
      "\n",
      " shared y in client: ArithmeticSharedRingTensor\n",
      " value:tensor([[-7272982348057305859,  5783740582566452664],\n",
      "        [ -150646293731826946,  1493090933781631187]], device='cuda:0') \n",
      " dtype:float \n",
      " scale:65536\n",
      " party:1\n"
     ]
    }
   ],
   "source": [
    "from config.base_configs import DEVICE\n",
    "\n",
    "# data belong to server\n",
    "x = RingTensor.convert_to_ring(torch.tensor([[1.0, 2.0], [3.0, 4.0]], device=DEVICE))\n",
    "# data belong to client\n",
    "y = RingTensor.convert_to_ring(torch.tensor([[-1.0, 2.0], [4.0, 3.0]], device=DEVICE))\n",
    "\n",
    "# split x into 2 parts\n",
    "X = ArithmeticSharedRingTensor.share(x, 2)\n",
    "\n",
    "# split y into 2 parts\n",
    "Y = ArithmeticSharedRingTensor.share(y, 2)\n",
    "\n",
    "# server shares x1 to client\n",
    "server.send(X[1])\n",
    "# client receives x1 from server\n",
    "x1 = client.receive()\n",
    "\n",
    "# client shares y0 to server\n",
    "client.send(Y[0])\n",
    "# server receives y0 from client\n",
    "y0 = server.receive()\n",
    "\n",
    "# convert RingTensor to ASS\n",
    "# server\n",
    "shared_x_0 = ArithmeticSharedRingTensor(X[0], server)\n",
    "shared_y_0 = ArithmeticSharedRingTensor(y0, server)\n",
    "\n",
    "print(\"\\n shared x in server:\", shared_x_0)\n",
    "print(\"\\n shared y in server:\", shared_y_0)\n",
    "\n",
    "# client\n",
    "shared_x_1 = ArithmeticSharedRingTensor(x1, client)\n",
    "shared_y_1 = ArithmeticSharedRingTensor(Y[1], client)\n",
    "print(\"\\n shared x in client:\", shared_x_1)\n",
    "print(\"\\n shared y in client:\", shared_y_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:55.284279Z",
     "start_time": "2024-03-21T11:20:55.115373Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Secret Restoring\n",
    "If you want to restore the original value by the share, you can use the ```restore()``` method, which returns a ```RingTensor``` value, and then the ```convert_to_real_field``` can recover the result.\n",
    "In this tutorial, we only print the recovered results on the server side."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " x after restoring: tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# restore share_x\n",
    "# server\n",
    "def restore_server():\n",
    "    restored_x = shared_x_0.restore()\n",
    "    real_x = restored_x.convert_to_real_field()\n",
    "    print(\"\\n x after restoring:\", real_x)\n",
    "\n",
    "# client\n",
    "def restore_client():\n",
    "    shared_x_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=restore_server)\n",
    "client_thread = threading.Thread(target=restore_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:55.299955Z",
     "start_time": "2024-03-21T11:20:55.286367Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Operations\n",
    "Next, we'll show you how to use arithmetic secret sharing to achieve secure two-party computation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Arithmetic Operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Addition tensor([[0., 4.],\n",
      "        [7., 7.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "# restore result\n",
    "def addition_server():\n",
    "    res_0 = shared_x_0 + shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\nAddition\", result_restored)\n",
    "\n",
    "def addition_client():\n",
    "    res_1 = shared_x_1 + shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=addition_server)\n",
    "client_thread = threading.Thread(target=addition_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:55.315597Z",
     "start_time": "2024-03-21T11:20:55.302043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtraction tensor([[ 2.,  0.],\n",
      "        [-1.,  1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Subtraction\n",
    "# restore result\n",
    "def subtraction_server():\n",
    "    res_0 = shared_x_0 - shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\nSubtraction\", result_restored)\n",
    "\n",
    "def subtraction_client():\n",
    "    res_1 = shared_x_1 - shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=subtraction_server)\n",
    "client_thread = threading.Thread(target=subtraction_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:55.331058Z",
     "start_time": "2024-03-21T11:20:55.316607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiplication tensor([[-1.,  4.],\n",
      "        [12., 12.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Multiplication\n",
    "# restore result\n",
    "def multiplication_server():\n",
    "    res_0 = shared_x_0 * shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\nMultiplication\", result_restored)\n",
    "\n",
    "def multiplication_client():\n",
    "    res_1 = shared_x_1 * shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=multiplication_server)\n",
    "client_thread = threading.Thread(target=multiplication_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:55.362370Z",
     "start_time": "2024-03-21T11:20:55.332115Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Since all the beaver triples used were generated during the offline phase, don't forget to generate the required matrix beaver triples before performing matrix multiplication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix Multiplication tensor([[ 7.0000,  8.0000],\n",
      "        [13.0000, 18.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "def matrix_multiplication_server():\n",
    "    # gen beaver triples in advance\n",
    "    triples = MatrixTriples.gen(1, x.shape, y.shape)\n",
    "    server.providers[MatrixTriples].param = [triples[0]]\n",
    "    server.send(triples[1])\n",
    "    server.providers[MatrixTriples].load_mat_beaver()\n",
    "    res_0 = shared_x_0 @ shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\nMatrix Multiplication\", result_restored)\n",
    "\n",
    "def matrix_multiplication_client():\n",
    "    client.providers[MatrixTriples].param = [client.receive()]\n",
    "    client.providers[MatrixTriples].load_mat_beaver()\n",
    "    res_1 = shared_x_1 @ shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=matrix_multiplication_server)\n",
    "client_thread = threading.Thread(target=matrix_multiplication_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:56.046780Z",
     "start_time": "2024-03-21T11:20:55.363382Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparison Operations\n",
    "The output results ```0``` and ```1``` correspond to the ``False`` and ``True`` values obtained from comparing the sizes of the torch tensors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(x < y) tensor([[0., 0.],\n",
      "        [1., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Less than\n",
    "def less_than_server():\n",
    "    res_0 = shared_x_0 < shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\n(x < y)\", result_restored)\n",
    "\n",
    "def less_than_client():\n",
    "    res_1 = shared_x_1 < shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=less_than_server)\n",
    "client_thread = threading.Thread(target=less_than_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:56.108906Z",
     "start_time": "2024-03-21T11:20:56.048823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(x <= y) tensor([[0., 1.],\n",
      "        [1., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Less than or equal\n",
    "def less_equal_server():\n",
    "    res_0 = shared_x_0 <= shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\n(x <= y)\", result_restored)\n",
    "\n",
    "def less_equal_client():\n",
    "    res_1 = shared_x_1 <= shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=less_equal_server)\n",
    "client_thread = threading.Thread(target=less_equal_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:56.171514Z",
     "start_time": "2024-03-21T11:20:56.109919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(x > y) tensor([[1., 0.],\n",
      "        [0., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Greater than\n",
    "def greater_than_server():\n",
    "    res_0 = shared_x_0 > shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\n(x > y)\", result_restored)\n",
    "\n",
    "def greater_than_client():\n",
    "    res_1 = shared_x_1 > shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=greater_than_server)\n",
    "client_thread = threading.Thread(target=greater_than_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:56.234787Z",
     "start_time": "2024-03-21T11:20:56.173590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(x >= y) tensor([[1., 1.],\n",
      "        [0., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Greater than or equal\n",
    "def greater_equal_server():\n",
    "    res_0 = shared_x_0 >= shared_y_0\n",
    "    result_restored = res_0.restore().convert_to_real_field()\n",
    "    print(\"\\n(x >= y)\", result_restored)\n",
    "\n",
    "def greater_equal_client():\n",
    "    res_1 = shared_x_1 >= shared_y_1\n",
    "    res_1.restore()\n",
    "\n",
    "server_thread = threading.Thread(target=greater_equal_server)\n",
    "client_thread = threading.Thread(target=greater_equal_client)\n",
    "\n",
    "server_thread.start()\n",
    "client_thread.start()\n",
    "client_thread.join()\n",
    "server_thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:20:56.297190Z",
     "start_time": "2024-03-21T11:20:56.235798Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
